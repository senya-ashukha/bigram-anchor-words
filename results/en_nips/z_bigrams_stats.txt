neural network	8663
thi paper	2803
hidden unit	2656
train set	2351
figur show	1652
learn algorithm	1456
data set	1399
inform process	1353
shown figur	1342
train data	1258
recept field	1233
neural net	1162
process system	1147
neural inform	1142
test set	1129
hidden layer	1090
neural comput	1074
advanc neural	1007
thi case	986
reinforc learn	953
basi function	948
output unit	946
thi work	922
learn rate	902
comput scienc	895
gradient descent	888
learn rule	856
mit press	815
network train	770
speech recognit	768
time step	765
morgan kaufmann	757
new york	737
network model	734
error rate	733
input vector	727
thi problem	717
technic report	695
machin learn	689
fix point	687
wa use	667
input output	666
valu function	664
gener error	663
use thi	657
weight vector	656
pattern recognit	649
train exampl	642
probabl distribut	616
input space	610
data point	606
cost function	605
input pattern	599
network use	595
network learn	586
recurr network	580
state space	578
thi model	572
net work	568
network architectur	568
signal process	567
thi approach	557
san mateo	555
onli one	554
time seri	549
fire rate	537
input unit	528
markov model	514
model use	513
network wa	513
thi section	507
maximum likelihood	505
visual cortex	503
train network	501
standard deviat	500
mean field	500
use train	496
dynam system	495
artifici neural	492
ieee tran	489
associ memori	486
squar error	485
wa support	479
activ function	478
object function	473
shown fig	473
see figur	473
dure train	470
princip compon	467
lower bound	464
upper bound	457
transfer function	455
function approxim	452
error function	451
mixtur model	443
time constant	441
train test	439
spike train	439
support vector	435
hidden markov	433
algorithm use	433
radial basi	430
featur vector	423
number hidden	421
random variabl	420
work wa	417
supervis learn	417
larg number	414
experiment result	408
analog vlsi	403
output layer	403
intern represent	401
compon analysi	400
dynam program	397
weight decay	395
nearest neighbor	389
wa train	388
mont carlo	387
artifici intellig	386
cognit scienc	386
special case	382
neural system	382
thi result	379
back propag	378
feedforward network	377
thi method	377
use neural	371
featur space	370
would like	367
ieee transact	367
input layer	361
recurr neural	361
mutual inform	357
fig show	357
local minima	355
covari matrix	354
network perform	352
network ha	351
thi algorithm	351
network thi	348
second order	347
intern confer	344
network output	343
learn curv	341
ocular domin	341
decis tree	340
institut technolog	339
probabl densiti	339
mean squar	336
gener model	332
describ abov	332
train pattern	332
depart comput	330
editor advanc	324
train use	322
initi condit	322
featur map	319
densiti estim	319
posterior probabl	318
left right	316
model thi	314
function use	314
speech signal	313
ha shown	313
time delay	312
phd thesi	312
boltzmann machin	311
scienc univers	311
synapt weight	311
gaussian mixtur	310
train error	309
input data	307
simul result	305
gener perform	303
press cambridg	302
use onli	302
energi function	298
higher order	297
recognit system	294
mateo morgan	292
independ compon	292
featur extract	289
method use	288
san diego	287
thi network	287
input signal	286
two differ	286
learn model	285
system use	284
multilay perceptron	284
learn system	284
solid line	283
parallel distribut	282
dure learn	281
onlin learn	281
gaussian nois	280
improv perform	280
weight updat	280
let denot	279
thi research	279
layer network	278
use model	277
test error	277
function thi	277
membran potenti	277
model select	277
gaussian distribut	277
unsupervis learn	276
mixtur expert	274
action potenti	273
test data	271
figur thi	271
predict error	270
result thi	269
spatial frequenc	268
result obtain	268
train algorithm	267
distribut process	267
next section	267
unit activ	266
number train	266
set size	264
rbf network	264
differenti equat	264
markov chain	264
visual system	263
thi type	261
also use	261
eye movement	260
output node	259
time scale	256
learn problem	256
model wa	256
network input	255
total number	254
data use	254
learn process	253
network weight	252
small number	252
number paramet	251
thi task	250
paper present	250
algo rithm	249
previou section	248
linear combin	247
weight sum	247
train sampl	247
use gener	247
paramet estim	246
network neural	246
thi system	246
fulli connect	246
input imag	244
unit output	243
gaussian process	243
output neuron	243
even though	241
comput vision	241
input variabl	240
show result	237
vector machin	237
forward model	236
transit probabl	236
result show	235
loss function	235
set train	235
learn task	235
nois level	234
func tion	234
recognit use	234
initi weight	233
classif problem	233
sampl size	233
may use	232
optim problem	232
first order	231
connectionist model	231
model paramet	231
number input	230
thi mean	230
object recognit	230
multilay network	229
hidden node	229
thi way	229
optim valu	228
posterior distribut	228
confer neural	227
order magnitud	227
condit probabl	227
output vector	226
linear model	226
model neuron	225
dash line	225
make use	225
given input	225
vector quantiz	225
nervou system	225
learn control	225
learn theori	223
backpropag network	223
note thi	223
use learn	222
howev thi	219
figur left	219
hebbian learn	218
show thi	217
well known	217
neuron model	216
train time	216
desir output	215
univers california	215
set use	215
posit neg	215
expect valu	214
previou work	213
dynam model	213
target function	212
input featur	211
spike neuron	211
sigmoid function	210
output valu	210
handwritten digit	209
unit hidden	209
gate network	209
output network	209
paper describ	208
comput model	208
genet algorithm	207
unit network	207
feedforward neural	207
singl neuron	207
one two	206
weight chang	206
thi studi	206
model ha	205
optic flow	205
continu speech	205
learn network	204
could use	204
function defin	204
valid set	202
algorithm wa	202
function network	202
learn time	202
densiti function	202
backpropag algorithm	202
cross valid	202
model neural	201
set consist	201
connect weight	201
data thi	201
inform theori	201
neuron activ	200
hinton william	200
learn ing	200
learn use	200
network comput	199
competit learn	199
pattern classif	199
take account	199
receiv input	199
set exampl	199
first layer	198
differ valu	198
research wa	197
threshold function	197
approach use	196
least squar	196
electr engin	195
nonlinear function	195
paramet valu	194
set input	194
veri larg	193
figur illustr	193
pattern gener	192
input network	192
function input	192
boolean function	191
degre freedom	191
set wa	191
activ unit	190
model learn	190
system ha	190
california institut	190
prior knowledg	189
tabl show	188
real time	188
rumelhart hinton	188
free energi	188
model base	188
thi point	188
state transit	187
tangent distanc	187
given set	187
kalman filter	187
real world	187
experi use	186
obtain use	186
motor command	186
updat rule	186
system page	186
learn method	185
hidden state	185
charact recognit	185
algorithm learn	185
perform thi	185
network hidden	185
univers press	185
weight network	185
euclidean distanc	185
statist mechan	185
later connect	185
use two	185
thi procedur	184
estim use	184
result shown	184
network gener	184
natur imag	183
optim polici	183
problem use	183
log likelihood	182
give rise	182
zero mean	182
system san	182
free paramet	182
distribut represent	182
comput simul	181
use standard	181
acad sci	181
compar perform	181
learn procedur	180
wide rang	180
improv gener	180
markov decis	179
finit state	179
experiment data	179
ed advanc	179
proc ieee	179
initi state	178
activ level	178
network one	178
academ press	178
second layer	178
thi allow	178
problem thi	178
unit input	178
weight space	177
see fig	177
set thi	176
perform network	176
learn thi	176
eye posit	176
input node	175
veri similar	175
weight matrix	175
excitatori inhibitori	175
thi process	175
current state	174
input neuron	174
function number	174
visual process	173
may also	173
number weight	173
valu thi	173
time thi	173
sy tem	172
error propag	172
function ha	172
set weight	172
hidden variabl	172
like thank	172
pyramid cell	172
project pursuit	171
control system	171
order paramet	171
depend onli	171
tempor differ	171
high dimension	171
analog neural	171
two class	171
layer unit	170
perform wa	170
veri small	170
rumelhart mcclelland	170
use differ	170
increas number	170
futur work	170
complex cell	170
cambridg mit	170
graphic model	170
belief network	169
network figur	169
data wa	169
second term	169
synapt input	168
mean varianc	168
algorithm base	168
train neural	168
activ pattern	168
model data	168
thi exampl	168
mixtur gaussian	168
model train	167
illustr figur	167
paramet set	167
thi lead	167
local minimum	167
penalti term	166
model predict	166
perform use	166
wa found	166
wa test	166
connect network	166
learn neural	165
perform well	165
thi wa	165
set paramet	165
result present	165
pattern activ	164
data gener	164
one use	164
prob lem	163
carnegi mellon	163
cell fire	163
present thi	163
section describ	162
first two	162
describ thi	162
use comput	162
system morgan	162
optim control	161
phi rev	161
acoust speech	161
wa chosen	161
one hidden	161
exampl thi	161
model gener	160
first term	160
start point	160
word recognit	160
head direct	160
thi architectur	160
point view	160
simul anneal	160
dot line	159
neuron network	159
thi data	159
algorithm ha	159
discuss thi	159
tune curv	159
per second	159
network size	159
use input	158
number iter	158
thi suggest	158
number unit	158
solv problem	157
solut thi	157
first second	157
pattern present	157
classif task	157
wa also	157
figur exampl	157
scienc foundat	157
function given	157
function form	156
state variabl	156
system thi	156
use simpl	155
network classifi	155
linear function	155
build block	155
also show	155
ani given	155
feed forward	155
biol cybern	154
imag process	154
weight valu	154
one ha	154
error signal	154
use algorithm	153
differ type	153
input thi	153
pro cess	153
input hidden	153
linear threshold	153
comput learn	153
problem learn	152
thi function	152
use estim	152
algorithm thi	152
support part	152
ha two	152
comput neural	151
network structur	151
steadi state	151
new algorithm	151
complex system	151
consist two	150
find optim	150
set test	150
thi would	150
simpl cell	149
prior probabl	149
direct select	149
converg rate	149
train procedur	149
function learn	148
power spectrum	148
lowpass filter	148
present result	148
comput complex	148
extern input	148
blind separ	147
paramet space	147
normal distribut	147
mellon univers	147
similar result	147
number neuron	147
sci usa	147
least one	147
error measur	146
field theori	146
shown tabl	146
work well	146
thi equat	146
onli small	146
one may	145
learn exampl	145
decis process	145
nation scienc	145
network paramet	145
comput use	145
recognit task	145
use backpropag	144
system model	144
see also	144
unit repres	144
model network	144
paramet use	144
unit thi	143
differ learn	143
problem solv	143
neuron fire	143
point thi	143
follow section	143
respons function	143
layer neuron	143
stochast approxim	142
three differ	142
cambridg univers	142
distanc measur	142
test pattern	142
given data	142
control problem	142
learn machin	142
result use	142
digit recognit	142
wa set	142
one output	141
use network	141
threshold circuit	141
error bar	141
set point	141
estim probabl	141
thi set	141
phase transit	141
thi effect	141
unit use	141
exampl use	141
network implement	140
thi done	140
feedback control	140
take place	140
uniform distribut	140
thi techniqu	140
case thi	140
number exampl	140
paramet vector	140
class label	140
work ha	140
base upon	139
visual field	139
one way	139
depart electr	139
neural model	139
network consist	139
net input	139
network ieee	139
paramet model	139
linear regress	139
result network	139
kernel function	139
factor analysi	139
perform better	139
learn intern	138
first step	138
imag use	138
thi ha	138
hopfield network	138
institut physic	138
latent variabl	137
ha use	137
valu use	137
rate converg	137
dot product	137
function time	137
likelihood estim	137
estim paramet	137
proceed ieee	137
state vector	137
naval research	136
use test	136
offic naval	136
connect strength	136
describ section	136
wa obtain	136
observ data	136
output thi	135
william learn	135
state action	135
conclus thi	135
close relat	135
synapt strength	135
thi may	135
commonli use	135
network simul	135
error thi	134
project onto	134
kaufmann san	134
adapt network	134
simpl model	134
morgan kaufman	134
correctli classifi	134
nonlinear model	134
nois varianc	134
vlsi neural	134
algorithm converg	134
earli stop	133
connectionist network	133
function comput	133
face recognit	133
thi experi	133
comput effici	133
sourc separ	133
fals alarm	133
ganglion cell	133
inner product	133
volum page	133
spike time	132
section present	132
network function	132
probabl estim	132
prior distribut	132
learn dynam	132
bayesian network	132
probabl model	132
veri simpl	132
gener thi	132
thi impli	132
joint distribut	132
use follow	132
target valu	132
model also	132
paramet thi	132
natl acad	131
discret time	131
figur network	131
wa perform	131
proc natl	131
research center	131
two set	131
recognit rate	131
statist model	131
use local	131
model describ	130
wa done	130
randomli select	130
onli two	130
local linear	130
thi gener	130
perfor manc	130
reduc number	130
decis boundari	130
also shown	130
comput time	130
help discuss	129
use linear	129
striat cortex	129
conjug gradient	129
two input	129
comput power	129
space thi	129
figur plot	129
take valu	129
descript length	128
appli thi	128
second deriv	128
lagrang multipli	128
weight function	128
layer hidden	128
valu iter	128
higher level	128
time figur	128
use gaussian	127
global optim	127
two layer	127
weight thi	127
primari visual	127
differ two	127
two type	127
kaufmann publish	127
sensori input	126
larg enough	126
global minimum	126
posit definit	126
best perform	126
set data	126
activ neuron	126
infor mation	126
input dimens	125
univers pittsburgh	125
motor control	125
activ learn	125
gibb sampl	125
condit distribut	125
robot arm	125
later inhibit	125
input sequenc	125
research group	125
state machin	125
paper show	125
unit weight	125
mani differ	125
singl layer	125
thi properti	125
decis problem	124
neu ral	124
algorithm neural	124
thi give	124
stabl state	124
system perform	124
unit one	124
class function	124
dynam rang	124
fourier transform	124
thi assumpt	124
gener case	124
theorem let	124
stochast process	123
number state	123
use weight	123
vlsi implement	123
orient select	123
optim solut	123
decis region	123
step size	123
finit set	123
input distribut	123
joint confer	123
state thi	123
massachusett institut	123
wa shown	123
achiev thi	123
set contain	123
belief state	123
american institut	123
approxim error	123
weight connect	122
iter algorithm	122
partial observ	122
result indic	122
map input	122
follow theorem	122
proceed intern	122
ha also	122
algorithm perform	122
time interv	122
take advantag	122
local model	121
san francisco	121
jordan jacob	121
valu weight	121
depend upon	121
real number	121
algorithm describ	121
data model	121
time cours	120
predict model	120
continu time	120
use predict	120
weight input	120
network control	120
classifi use	120
adapt control	120
implement use	119
determin whether	119
state time	119
mixtur densiti	119
network approach	119
method base	119
network shown	119
linear system	119
synapt connect	119
line segment	118
use method	118
block diagram	118
classif perform	118
use determin	118
thi inform	118
sinc thi	118
neural activ	117
without ani	117
randomli chosen	117
show perform	117
backpropag learn	117
cortic cell	117
solv thi	117
one would	117
differ input	116
use experi	116
significantli better	116
use set	116
mixtur compon	116
intern joint	116
learn predict	116
use approxim	116
two dimension	116
neuron output	116
present model	116
connect input	116
nonlinear dynam	116
cortic neuron	116
short term	116
float gate	115
unit wa	115
network dynam	115
expert network	115
salienc map	115
search space	115
error train	115
comput system	115
tangent vector	115
thi approxim	115
di tribut	115
univers toronto	114
network base	114
use gradient	114
wide varieti	114
network predict	114
techniqu use	114
use inform	114
data base	114
result report	114
technolog pasadena	114
initi valu	114
control signal	113
classif error	113
weight set	113
next state	113
input current	113
result suggest	113
perform measur	113
one input	113
basi vector	113
one time	113
present input	113
thi form	113
popul code	113
train process	113
invers model	112
main result	112
dimension space	112
train thi	112
use singl	112
field approxim	112
problem find	112
network approxim	112
parallel comput	112
output space	112
result experi	112
see text	112
hidden output	112
one might	112
would requir	111
high frequenc	111
regress problem	111
absolut valu	111
wa present	111
vector repres	111
system volum	111
number node	111
condit densiti	111
randomli gener	111
pat tern	111
wa gener	111
optim brain	111
process use	111
wiley son	111
joint probabl	111
